---
title: "Future US Transportation Vulnerable Due to Lack of AI Implementation Legislation"
date: 2022-12-05
---

  The gaping hole in US legislation regarding Artificial Intelligence (AI) adoption will result in significant vulnerabilities getting introduced in the US transportation system. The advent of self-driving, or driverless, cars are taking the world by storm, but few are talking about the fundamental issues in these vehicles’ AI models. These issues include easy deception, hacking, and manipulation.  Many expect these AI-powered vehicles to become mainstream by the 2030s but heavily introduced in the late 2020s or early 2030s.  While this gives time for the world to create methods and procedures for adopting transportation AI, the pace of government handling modern technologies is worrisome; this is on top of the fact that multiple bills regarding this topic have already died in congress.  Ensuring regulation and a standardized framework for transportation AI adoption is paramount as humanity takes this next significant transportation step.

AI isn’t everywhere. Yet.
	AI impacts most people’s lives in numerous ways; these areas range from agriculture to photography to healthcare.  While AI isn’t everywhere, it soon will be.  While not apparent yet, transportation AI is beginning to create an impact that many are feeling. AI has been introduced into Google’s bus alert and prediction system. At least 60 million people use this feature to create a more efficient commute. AI is being introduced into trucking in New Zealand. Not only are camera’s being installed in cabs, analyzing for signs of distraction or impairment, but that data is also powering AI-created trucker training in India. Railroads are using AI to predict track conditions, air travel is being streamlined and increasingly commercialized, and even bike-share platforms are using AI to reduce the hassle of using the platform, and educating cities on how to improve conditions to increase bike use.  While these are small areas in the large calculus that is global transportation, they are providing a glimpse of what may come as a result of transportation’s AI implementation.
	AI transportation integration is being researched and looked at in a multitude of applications; transportation, as society knows it, is expected to change drastically in the next couple of decades. One of the main talking points is self-driving and driverless vehicles. However, other advancements are coming. AI-powered transportation applications to reduce overall traffic, driverless taxis, driverless trucking, remote-controlled cargo ships, and more.  Two areas just listed should be especially considered when thinking about AI vulnerabilities: cargo ships and trucking. It is estimated that 80% of global trade is handled via sea.  Looking back at the Suez Canal shipping block in 2021, it was estimated to have a daily cost of $9.6 billion.  This canal blockage, lasting only six days, but further injured an already struggling global supply chain by adding wait times of as many as two weeks.  Trucking moves about 72% of the US’s freight in terms of weight,  meaning it is a significant piece in the overall national trade picture. The introduction of AI into any area of transportation is something to watch. However, introducing personal vehicles, maritime cargo, and trucking should garner particular concern as they are so critical in the day-to-day infrastructure that runs the world. Without careful consideration, these complex processes could quickly become very vulnerable to disruption and harm, potentially leaving many devastated for years to come.

Threats to AI Are Simple and Apparent to Many, Too Many

  The threats that face AI and AI-powered systems are not new, nor are they overly complex, allowing many to participate as they wish. The traditional hacking method is rampant , but deception and manipulation are of particular concern as there haven’t been many technologies that were susceptible to that in the past. This creates the necessity for AI integration to be looked at differently from a security standpoint.
	One example of an easily manipulated automation in transportation comes from Tesla. Elon Musk has even admitted that a stop sign on a t-shirt would stop a tesla’s autopilot.  There are more reports from drivers experiencing dangerous situations when stop signs are an odd size  or even a stop sign that appears on a billboard.  So, if someone with malicious intent knows someone’s route heading home and knows they use autopilot, they would easily be able to manipulate their driving experience. This is an effortless, easily executed, and anonymous way to attack someone. 
	Data poisoning is another way that attackers could hack AI.  Suppose a bad actor can compromise the self-driving or automation model of any AI involved in transportation and taint it with bad data. In that case, it could lead to that AI acting incorrectly until data scientists discover the errors. These attacks are especially likely in a self-learning system. The system takes user inputs to base its future behavior on. If a self-input AI gets implemented into an intersection, someone could learn how to feed it information with the long-term goal of making it behave incorrectly. The industry is getting better at protecting data, but the rate of data breaches each year is increasing almost exponentially.  This leads us to the conclusion that it is not if AI models get intentionally poisoned but when.
	In recent months, there has been an increasing spotlight on clothing that can hide the subject from computer vision AI.  These could be used to cover road signs, people, or any number of objects, allowing autonomous vehicles to ram into them, as they do not “see” them. These clothes are mostly being talked about in the context of hiding individuals in an AI-driven surveillance state. However, nothing stops others from using these patterns for other nefarious purposes. 
	In the implementation of AI, only two things are sure: The implementation is coming, and adversarial ingenuity is vast. The list of hypothetical situations of how simple tricks can fool these autonomous AI models is long. That list grows each year alongside all the new ways researchers think of implementing AI into the transportation system.
 
Lack of System Reliance Keeping People Safe, for Now

  While many alarm bells are being raised, there have yet to be many attacks on these systems. This may be due to society’s little reliance on them so far. Attackers, bad actors, nation-states, etc., like to target systems and vulnerabilities that will disrupt the way of life or a critical system component. Currently, autonomous vehicles and transportation AI have not needed to be relied on. However, we, as a society, are slowly making ourselves dependent on them. Once society depends on AI in our transportation network, it’ll open up a new attack surface for adversaries.
  This pattern of not attacking a system based on reliance can be seen with social media and cyberbullying. The real dawn of social media was in 2004 when Myspace hit 1 million monthly users.  One of the first infamous cases of cyberbullying occurred in 2007, with a 13-year-old girl on Myspace committing suicide.  Cyberbullying increased in popularity as social media did but reached a new dimension in the mid-2000s alongside the widespread adoption of smartphones. While this doesn’t suggest that social media is the reason for cyberbullying, it does show a key lesson to consider: Bad actors will act, drawn to different mediums upon which to act, and any new widely used system will become their new medium. AI-powered transportation and its vulnerabilities will be the latest medium for bad actors to act on. This creates a need for better regulation of the implementation. Otherwise, we may have another epidemic, which cyberbullying has become,  by having to play catch up legislatively.

Implementation Regulation, Framework is Key

  Passing legislation regarding AI-implemented transportation systems is key to getting ahead of the vulnerabilities our transportation system may inherit soon. Currently, a bill is trying to make its way through the legislative process. However, it currently has a poor outlook, with some analysts having it listed as having just a 2% chance of enactment.  While more bills may cover vehicle autonomy and transportation AI, the time is now, as future bills are not guaranteed. There have been multiple previous attempts, but all died while in congress. Using bi-partisan power to ensure the survival of the Self Drive act would ensure great strides in shoring up the resilience of the US transportation system as AI is increasingly implemented.
	Furthermore, a valuable action item for the Senate committee on commerce, science, and transportation would be to work with the National Institute of Standards and Technology (NIST) on creating a framework outlining standards that producers of AI-powered systems must meet before they are allowed to add their products into the transportation system. NIST has been an incredible resource in research and developing other widely used technical and security-minded frameworks.  Their contributions to an AI implementation framework would ensure the safer rollout of AI into the US transportation systems. This would increase safety and empower the US to continue to be a leader in the transportation revolution the world currently faces.
